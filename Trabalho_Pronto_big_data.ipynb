{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leticiaholsback/Aprendizado/blob/main/Trabalho_Pronto_big_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ockWpfoQ2HIv"
      },
      "source": [
        "# Comandos para realização do trabalho da matéria de Big Data com uso da biblioteca PySpark.\n",
        "\n",
        "## <font color=red>Observação importante:</font>\n",
        "\n",
        "<font color=yellow>Trabalho realizado com uso da biblioteca pandas não será aceito!</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lunxNZmn2HIy"
      },
      "source": [
        "## Upload do arquivo `imdb-reviews-pt-br.csv` para dentro do Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MND3Mjx32HIz",
        "outputId": "6ebf1dda-a75e-485b-ea36-499041157dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-08-28 11:01:57--  https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49549692 (47M) [application/zip]\n",
            "Saving to: ‘imdb-reviews-pt-br.zip’\n",
            "\n",
            "imdb-reviews-pt-br. 100%[===================>]  47.25M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-08-28 11:01:58 (408 MB/s) - ‘imdb-reviews-pt-br.zip’ saved [49549692/49549692]\n",
            "\n",
            "Archive:  imdb-reviews-pt-br.zip\n",
            "  inflating: imdb-reviews-pt-br.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/N-CPUninter/Big_Data/main/data/imdb-reviews-pt-br.zip -O imdb-reviews-pt-br.zip\n",
        "!unzip imdb-reviews-pt-br.zip\n",
        "!rm imdb-reviews-pt-br.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq3SgoF72HI0"
      },
      "source": [
        "## Instalação manual das dependências para uso do pyspark no Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOyZZFCT2HI1",
        "outputId": "9572d12b-e22f-42ee-b0f4-26a0e496a9a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=2355b713a24e8c4d82fea110cfc5a94038a821aca1ff7fda5d3dc3387a3a1344\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aruzK3uS2HI1"
      },
      "source": [
        "## Importar, instanciar e criar a SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfKfrFmR2HI1"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "appName = \"PySpark Trabalho de Big Data\"\n",
        "master = \"local\"\n",
        "\n",
        "spark = SparkSession.builder.appName(appName).master(master).getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbKzGdPm2HI2"
      },
      "source": [
        "## Criar spark dataframe do CSV utilizando o método rtead.csv do spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3SthTgK2HI2"
      },
      "outputs": [],
      "source": [
        "imdb_df = spark.read.csv('imdb-reviews-pt-br.csv',\n",
        "                         header=True,\n",
        "                         quote=\"\\\"\",\n",
        "                         escape=\"\\\"\",\n",
        "                         encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "VYf2cKOdKDkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"CalculatingNegativeSentiments\").getOrCreate()"
      ],
      "metadata": {
        "id": "52XY1KlQMpzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df = df.filter(df.sentiment == \"neg\")"
      ],
      "metadata": {
        "id": "r3QFsmTCMt5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_sum = negative_df.selectExpr(\"sum(id)\").collect()[0][0]\n"
      ],
      "metadata": {
        "id": "PhUEZ6AHMxrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Leticia, RU: 4025500, coonsegui chegar no resultado da soma dos 'id' dos filmes classificados como negativos em:\", total_sum)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-MthZtZM15A",
        "outputId": "30f451dc-7d05-4cd8-8ce1-e5983b05d6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Leticia, RU: 4025500, coonsegui chegar no resultado da soma dos 'id' dos filmes classificados como negativos em: 247015948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def map_sentiment_id(row):\n",
        "    sentiment = row.sentiment\n",
        "    id_value = int(row.id)\n",
        "    return (sentiment, id_value)"
      ],
      "metadata": {
        "id": "GuaZgJX1KExM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"MapSentimentId\").getOrCreate()"
      ],
      "metadata": {
        "id": "PGqYtJ0uKE_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "gviv6MYyKFJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_id_rdd = df.rdd.map(map_sentiment_id)\n"
      ],
      "metadata": {
        "id": "XhmrM2SRKFU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_id_rdd.take(10))"
      ],
      "metadata": {
        "id": "QqQzFDS7MAZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resultado do mapeamento:\")\n",
        "for result in sentiment_id_rdd.take(10):\n",
        "    print(\"Sentiment:\", result[0], \"ID:\", result[1])"
      ],
      "metadata": {
        "id": "OEb0G3mWMAI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentiment_id_rdd.take(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MdEQrIFKQEF",
        "outputId": "34d37ea5-c185-4633-9f00-0e3cdb79e43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('neg', 1), ('neg', 2), (' exceto Paxton e o sem-teto e todos recebem o que merecem. Os dois únicos negros que podem atuar são o sem-teto e o viciado', 3), ('neg', 4), ('neg', 5), (' excuse me', 6), ('neg', 7), (' forcedly so', 8), (' and more talk. Youll get to see the less than stellar cast of three as they talk on the bus', 9), ('neg', 10)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Resultado do mapeamento:\")\n",
        "for result in sentiment_id_rdd.take(10):\n",
        "    print(\"Sentiment:\", result[0], \"ID:\", result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwoVEDD6KQOu",
        "outputId": "836fae4c-e665-486e-fa90-8463ce87fb3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado do mapeamento:\n",
            "Sentiment: neg ID: 1\n",
            "Sentiment: neg ID: 2\n",
            "Sentiment:  exceto Paxton e o sem-teto e todos recebem o que merecem. Os dois únicos negros que podem atuar são o sem-teto e o viciado ID: 3\n",
            "Sentiment: neg ID: 4\n",
            "Sentiment: neg ID: 5\n",
            "Sentiment:  excuse me ID: 6\n",
            "Sentiment: neg ID: 7\n",
            "Sentiment:  forcedly so ID: 8\n",
            "Sentiment:  and more talk. Youll get to see the less than stellar cast of three as they talk on the bus ID: 9\n",
            "Sentiment: neg ID: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "j9EyyyPkL7C8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEiksQOr2HI3"
      },
      "source": [
        "# Questão 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questão – Qual o valor da soma de todos os campos “id” dos filmes classificados como negativos para o banco de dados “imdb-reviews-pt-br.csv”\n",
        "Leticia 4025500"
      ],
      "metadata": {
        "id": "FA68-lC3McKI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6GIydjP2HI3"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e o \"id\" como valor do tipo inteiro"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Função MAP - Leticia 4025500"
      ],
      "metadata": {
        "id": "42PwsOoyQcET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n"
      ],
      "metadata": {
        "id": "Ed-yWZaTQaNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"WordCount\").getOrCreate()"
      ],
      "metadata": {
        "id": "Y-14cSswVkwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n"
      ],
      "metadata": {
        "id": "-lkCU6XhQbWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df = df.filter(df.sentiment == \"neg\")"
      ],
      "metadata": {
        "id": "ILPhvzP3QbfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_function(row):\n",
        "    text = row[\"text_pt\"]\n",
        "    words = text.split()\n",
        "    return [(word, 1) for word in words]"
      ],
      "metadata": {
        "id": "fKTjy9CiVrYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cria funções de REDUCE:\n",
        "- Criar função de reduce para somar os IDs por \"sentiment\"."
      ],
      "metadata": {
        "id": "zCJ432-7RUc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_function(count1, count2):\n",
        "    return count1 + count2"
      ],
      "metadata": {
        "id": "xcARnoAOQ09E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicação do map/reduce e visualização do resultado"
      ],
      "metadata": {
        "id": "NcrRZqOFUhQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = negative_df.rdd.flatMap(map_function).reduceByKey(reduce_function)"
      ],
      "metadata": {
        "id": "sJjjyI_pQ1Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testar contagem\n",
        "result = word_counts.collect()\n",
        "for word, count in result:\n",
        "    print(f\"Palavra: {word}, Contagem: {count}\")"
      ],
      "metadata": {
        "id": "d0n1rGgUV3R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_word_count = word_counts.map(lambda x: x[1]).reduce(reduce_function)"
      ],
      "metadata": {
        "id": "M7YtbHC6Q1Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RU: 4025500 e o total de palavras nos textos negativos:\", total_word_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpl6jEYUsZ5",
        "outputId": "a461a6de-8e20-477e-b934-1efadf35303b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RU: 4025500 e o total de palavras nos textos negativos: 2415179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "d_RrgakTU0yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V2g4APL2HI4"
      },
      "source": [
        "# Questão 2:\n",
        "Prática 02 – Diferença do número de palavras totais de português para inglês dos textos negativos\n",
        "Questão – Contar palavras dos textos negativos e achar diferença de quantidade.\n",
        "ENUNCIADO: Nessa prática você deverá contar todas as palavras existentes nos textos negativos (Português e Inglês) e então deverá encontrar quantas palavras\n",
        "a mais, no total, os textos em português possuem.\n",
        "Para tal, crie um script em Python ou Scala e rode-o com sua máquina virtual Hadoop ou Spark ou PySpark, como feito na prática 1.\n",
        "É necessário se preocupar em filtrar corretamente as avaliações de filmes para que apenas os textos marcados como negativos sejam contabilizados.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na-0dgaR2HI4"
      },
      "source": [
        "## Criar funções de MAP:\n",
        "- Criar função para mapear o \"sentiment\" como chave e uma tupla com a soma das palavras de cada texto como valor."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "5FyLV1M1ZZAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"CountingWords\").getOrCreate()"
      ],
      "metadata": {
        "id": "wmlmDZXKZZIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"/content/imdb-reviews-pt-br.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "p1eSFd7xzfLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df = df.filter(df.sentiment == \"neg\")"
      ],
      "metadata": {
        "id": "9BNOGZsFzful"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_words(text):\n",
        "    return len(text.split())"
      ],
      "metadata": {
        "id": "aXQE9PUhzlOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_function(row):\n",
        "    sentiment = row.sentiment\n",
        "    pt_count = count_words(row.text_pt)\n",
        "    en_count = count_words(row.text_en)\n",
        "    return (sentiment, (pt_count, en_count))"
      ],
      "metadata": {
        "id": "6KZr_jf47Xpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ7LI-Cc2HI5"
      },
      "source": [
        "## Cria funções de REDUCE:\n",
        "\n",
        "- Criar função de reduce para somar o numero de palavras de cada texto português e inglês por \"sentiment\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_function(x, y):\n",
        "    pt_count = x[0] + y[0]\n",
        "    en_count = x[1] + y[1]\n",
        "    return (pt_count, en_count)"
      ],
      "metadata": {
        "id": "M0pvsllhzeQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Xq7A8fPzdcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A27rYZNd2HI5"
      },
      "source": [
        "## Aplicação do map/reduce e visualização do resultado\n",
        "\n",
        "1. Aplicar o map/reduce no seu dataframe spark e realizar o collect() ao final\n",
        "2. Selecionar os dados referentes aos textos negativos para realizar a subtração.\n",
        "3. Realizar a subtração das contagens de palavras dos textos negativos para obter o resultado final"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_counts = negative_df.rdd.map(map_function).reduceByKey(reduce_function)"
      ],
      "metadata": {
        "id": "a2ugX30YaLqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = word_counts.collect()"
      ],
      "metadata": {
        "id": "zpgiyHC10cSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentiment, (pt_count, en_count) in result:\n",
        "    print(f\"RU:4025500 e o Sentimento é: {sentiment}, e as Contagens de Palavras em Português e Inglês são: {pt_count} - {en_count}\")"
      ],
      "metadata": {
        "id": "kA1UIStw9MAY",
        "outputId": "bedd6e87-2edf-4847-8383-315cf86db763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RU:4025500 e o Sentimento é: neg, e as Contagens de Palavras em Português e Inglês são: 2415179 - 2399150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt_count = next((pt_count for sentiment, (pt_count, en_count) in result if sentiment == \"neg\"), 0)\n",
        "en_count = next((en_count for sentiment, (pt_count, en_count) in result if sentiment == \"neg\"), 0)"
      ],
      "metadata": {
        "id": "opC1u9Ge0ca0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "difference = pt_count - en_count"
      ],
      "metadata": {
        "id": "sRXaqWny6I7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Meu RU é: 4025500 e a diferença das palavras entre português e inglês, feitas por meio de subtração é de:\", difference)"
      ],
      "metadata": {
        "id": "azF0KKvd6Iwv",
        "outputId": "33dab7ef-7b0d-478f-b06c-0eef071e2e2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meu RU é: 4025500 e a diferença das palavras entre português e inglês, feitas por meio de subtração é de: 16029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "YVIo3qv09b0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0ly1yZa9c-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZNZ0ilf9dGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Ru: 4025500 - e a diferença das palavras entre português e inglês é de:\", difference)"
      ],
      "metadata": {
        "id": "2USB6ir30cjz",
        "outputId": "7a74dcbc-d2a2-4534-ebf0-c72cd0f13bbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferença no total de palavras entre português e inglês: 2415179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizar o resultado coleta e imprimir\n",
        "result = word_counts.collect()\n",
        "for sentiment, count in result:\n",
        "    print(f\"RU4025500 - O Sentimento é: {sentiment}, e as Contagens de Palavras são: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnnQB49jaQws",
        "outputId": "5ad2b4bc-ca32-43fa-a985-46b377344fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RU4025500 - O Sentimento é: neg, e as Contagens de Palavras são: 2415179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "D_EwXF3o0mc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "32gtn1Y40mkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTeP4-YI0mrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializar a sessão Spark\n",
        "spark = SparkSession.builder.appName(\"WordCountDifference\").getOrCreate()\n",
        "\n",
        "# Ler o arquivo CSV como um DataFrame\n",
        "df = spark.read.csv(\"/content/imdb-reviews-pt-br.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Filtrar linhas com sentimento negativo\n",
        "negative_df = df.filter(df.sentiment == \"neg\")\n",
        "\n",
        "# Função de MAP para contar palavras\n",
        "def map_function(row):\n",
        "    sentiment = row[\"sentiment\"]\n",
        "    text = row[\"text_pt\" if sentiment == \"neg\" else \"text_en\"]\n",
        "    words = text.split()\n",
        "    return (sentiment, len(words))\n",
        "\n",
        "# Função de REDUCE para somar contagens de palavras\n",
        "def reduce_function(count1, count2):\n",
        "    return count1 + count2\n",
        "\n",
        "# Aplicar a função de MAP e REDUCE\n",
        "word_counts = negative_df.rdd.map(map_function).reduceByKey(reduce_function)\n",
        "\n",
        "# Filtrar contagem de palavras para textos em português e inglês\n",
        "pt_count = word_counts.filter(lambda x: x[0] == \"neg\").map(lambda x: x[1]).collect()[0]\n",
        "en_count = word_counts.filter(lambda x: x[0] == \"neg_en\").map(lambda x: x[1]).collect()\n",
        "\n",
        "# Verificar se há contagem de palavras em inglês e calcular a diferença\n",
        "difference = pt_count - en_count[0] if en_count else pt_count\n",
        "\n",
        "# Imprimir o resultado da diferença\n",
        "print(\"Diferença no total de palavras entre português e inglês:\", difference)\n",
        "\n",
        "# Encerrar a sessão Spark\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "QD5D4bq10cs_",
        "outputId": "243b31a1-b52c-4a39-c991-9a0508d4f652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diferença no total de palavras entre português e inglês: 2415179\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}